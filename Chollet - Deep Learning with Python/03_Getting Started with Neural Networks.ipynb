{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch 3 - Getting Started with Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Anatomy of a Neural Network\n",
    "\n",
    "Training a neural network revolves around the following objects:\n",
    "\n",
    "- **Layers**, which are combined into a **network** (or **model**)\n",
    "\n",
    "- The **input data** and corresponding **targets**\n",
    "\n",
    "- The **loss function**, which defines the feedback signal used for learning\n",
    "\n",
    "- The **optimizer**, which determines how learning proceeds\n",
    "\n",
    "\n",
    "\n",
    "![NN1](Images/03_01.jpg)\n",
    "\n",
    "\n",
    "The network maps the input data to predictions. The loss function then compares these predictions to the targets, producing a loss value: a measure of how well the network's predictions match what was expected. The optimizer uses this loss value to update the network's weights. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 3.1.1 Layers: the Building Blocks of Deep Learning\n",
    "\n",
    "\n",
    "The **layer** is the fundamental data structure in neural networks. It is a data-processing module that takes one or more tensors as input and outputs one or more tensors. \n",
    "\n",
    "Some layers are stateless, but they more frequently have a state: the layer's **weights**, one or several tensors learned with stochastic gradient descent, which together contain the network's knowledge. \n",
    "\n",
    "Different layers are appropriate for different tensor formats and different types of data processing. \n",
    "\n",
    "- **Dense Layers**: Simple vector data stored in 2D tensors of shape (samples, features) is often processed by densely connected layers, also called fully connected or dense layers (the Dense class in Keras).\n",
    "\n",
    "- **Recurrent Layers**: Sequence data stored in 3D tensors of shape (samples, timesteps, features), is typically processed by recurrent layers such as an LSTM layer.\n",
    "\n",
    "- **2D Convolution Layers**: Image data stored in 4D tensors is usually processed by 2D convolution layers (Conv2D).\n",
    "\n",
    "\n",
    "Building deep-learning models in Keras is done by clipping together compatible layers to form useful data-transformation pipelines. The notion of **layer compatibility** here refers specifically to the fact that every layer will only accept input tensors of a certain shape and will return output tensors of a certain shape.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Example:\n",
    "(A dense layer with 32 output units)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "\n",
    "layer = layers.Dense(32, input_shape=(784, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating a layer that will only accept 2D tensors as input where the first dimension is 784. Since axis 0 is unspecified, any value would be accepted. This layer will return a tensor where the first dimension has been transformed to be 32.\n",
    "\n",
    "This layer can only be connected to a downstream layer that expects 32-dimensional vectors as its input.\n",
    "\n",
    "When using Keras, you don't have to worry about compatibility because the layers you add to your models are dynamically built to match the shape of the incoming layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import models\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, input_shape=(784, )))\n",
    "model.add(layers.Dense(32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second layer didn't receive an input shape argument - instead, it automatically inferred its input shape as being the output shape of the layer that came before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Models: Networks of Layers\n",
    "\n",
    "The most common dee-learning model instance is a linear stack of layers, mapping a single input to a single output. You will also be exposed to a broader variety of network topologies:\n",
    "\n",
    "- Two-branch networks\n",
    "\n",
    "- Multihead networks\n",
    "\n",
    "- Inception blocks\n",
    "\n",
    "The topology of a network defines a **hypothesis space**. We defined machine learning as \"searching for useful representations of some input data, within a predefined space of possibilities, using guidance from a feedback signal.\" By choosing a network topology, you constrain your **space of possibilities** (hypothesis space) to a specific series of tensor operations, mapping input data to output data. Then you will look for a good set of values for the weight tensors involved in these tensor operations. \n",
    "\n",
    "\n",
    "Picking the right **network architecture** is more art than science, and although there are some best practices and principles you can rely on, only practice can help you become a proper neural-network architect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Loss Functions and Optimizers: Keys to Configuring the Learning Process\n",
    "\n",
    "\n",
    "Once you define a network architecture, you still have to choose\n",
    "\n",
    "- **A loss function (objective function)**: The quantity that will be minimized during training. It represents a measure of success for the task at hand.\n",
    "\n",
    "- **Optimizer**: Determines how the network will be updated based on the loss function. It implements a specific variant of stochastic gradient descent (SGD).\n",
    "\n",
    "\n",
    "A neural network that has multiple outputs may have multiple loss functions (one per output). But the gradient-descent process must be based on a single scalar loss value; so, for multiloss networks, all losses are combined (via averaging) into a single scalar quantity.\n",
    "\n",
    "\n",
    "Choosing the right objective function for the right problem is important: your network will take any shortcut it can, to minimize the loss; so if the objective doesn't fully correlate with success for the task at hand, your network will end up doing things you might not want. \n",
    "\n",
    "\n",
    "When it comes to common problems such as classification, regression, and sequence prediction, there are simple guidelines you can follow to choose the correct loss. Only when you're working on truly new research problems will you have to develop your own objective functions.\n",
    "\n",
    "For example:\n",
    "\n",
    "- For a two-class classification problem, you'll use binary crossentropy\n",
    "\n",
    "- For a many-class classification problem, you'll use categorical crossentropy\n",
    "\n",
    "- For a regression problem, you'll use mean-squared error\n",
    "\n",
    "- For a sequence-learning problem, you'll use connectionist temporal classification (CTC).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Introduction to Keras\n",
    "\n",
    "Keras is a deep-learning framework for Python that provides a convenient way to define and train almost any kind of deep-learning model. Keras was initially developed for researchers, with the aim of enabling fast experimentation. Distributed under the MIT license, which means it can be freely used in commercial projects. \n",
    "\n",
    "Keras has the following features:\n",
    "\n",
    "- Allows the same code to run seamlessly on CPU or GPU.\n",
    "\n",
    "- Has a user-friendly API that makes it easy to quickly prototype deep-learning models.\n",
    "\n",
    "- Has build-in support for convolutional networks (for computer vision), recurrent networks (for sequence processing), and any combination of both.\n",
    "\n",
    "- Supports arbitrary network architectures: multi-input or multi-output models, layer sharing, model sharing, and so on. This means Keras is appropriate for building essentially any deep-learning model, from a generative adversarial network to a neural Turing machine.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Keras, Tensorflow, Theano, and CNTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Developing with Keras: a Quick Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Setting Up a Deep-Learning Workstation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Jupyter Notebooks: the Preferred Way to Run Deep-Learning Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Getting Keras Running: Two Options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Running Deep-Learning Jobs in the Cloud: Pros and Cons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 What is the Best GPU for Deep Learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Classifying Movie Reviews: a Binary Classification Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 The IMDB Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 Building Your Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4 Validating Your Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.5 Using a Trained Network to Generate Predictions on New Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.6 Further Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.7 Wrapping Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Classifying Newswires: a Multiclass Classification Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 The Reuters Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 Building Your Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.4 Validating Your Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.5 Generating Predictions on New Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.6 A Different Way to Handle the Labels and the Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.7 The Importance of Having Sufficiently Large Intermediate Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.8 Further Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.9 Wrapping Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Predicting House Prices: a Regression Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.1 The Boston Housing Price Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.2 Preparing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.3 Building Your Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.4 Validating Your Approach Using K-fold Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.5 Wrapping Up"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
